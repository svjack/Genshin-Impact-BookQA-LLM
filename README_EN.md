<!-- PROJECT LOGO -->
<br />
<p align="center">
  <h3 align="center">Genshin-Impact-BookQA-LLM</h3>

  <p align="center">
   		A Genshin Impact Book Question Answer Project supported by LLM (build by LangChain Haystack ChatGLM Mistral OLlama)
    <br />
  </p>
</p>

[ä¸­æ–‡ä»‹ç»](README.md)

## Brief introduction

### BackGround
[Genshin Impact](https://genshin.hoyoverse.com/en/) is an action role-playing game developed by miHoYo, published by miHoYo in mainland China and worldwide by Cognosphere, 
HoYoverse. The game features an anime-style open-world environment and an action-based battle system using elemental magic and character-switching. 

In the Game, some background settings are described by [Books](https://bbs.mihoyo.com/ys/obc/channel/map/189/68?bbs_presentation_style=no_header).
Let's take a shot.
<img src="imgs/book_shot.png" alt="Girl in a jacket" width="1050" height="950">

This project is an attempt to build Chinese Q&A on the different LLM support RAG system.

### Try Demo on the fly


|Name | HuggingFace Space link |
|---------|--------|
| Genshin Impact Book QA Haystack Demo ğŸ“ˆ | https://huggingface.co/spaces/svjack/genshin-impact-bookqa-haystack |

The Demo use Huggingface Inference Api that call [mistralai/Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2) to perform Q&A tasks.
Because the base model is not fintuned in Chinese but have more better inference capabilities than most below 10B models. You can take this deploy version as a free preview version. 

<img src="imgs/haystack_demo.png" alt="Girl in a jacket" width="1050" height="300"> <br/><br/>

## Installation and Running Results
### Install and Running Step
In the concept, the project can be divided into two parts, Basic_Part and LLM_Part. <br/>
* <b>Basic_Part</b> contains modules: [LangChain](https://github.com/langchain-ai/langchain) [SetFit](https://github.com/huggingface/setfit) you should install all of them By <br/>
```bash
pip install -r basic_requirements.txt
```
* <b>LLM_Part</b> are modules that you should choose one to install: [HayStack](https://github.com/deepset-ai/haystack) [chatglm.cpp](https://github.com/li-plus/chatglm.cpp) [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) [ollama](https://github.com/ollama/ollama)<br/> <br/>

Below are different LLM Repo types with their install and running command
|LLM Repo Name | LLM Model Name | Install Command in Linux | Run Gradio Demo Command |
|---------|--------|--------|--------|
| HayStack | Mistral-7B (based on huggingface inference) | pip install -r basic_requirements.txt && pip install haystack-ai==2.0.0b5 | python haystack_bookqa_gradio.py |
| llama-cpp-python | Mistral-7B (based on llama-cpp) | pip install -r basic_requirements.txt && pip install llama-cpp-python==0.2.55 | python mistral_bookqa_gradio.py |
| chatglm.cpp | chatglm3-6b | pip install -r basic_requirements.txt && pip install chatglm-cpp==0.3.1 | python chatglm_bookqa_gradio.py |
| ollama | Qwen-7B | pip install -r basic_requirements.txt && wget https://ollama.com/install.sh && sh ./install.sh && pip install ollama==0.1.6 && sudo systemctl start ollama | python ollama_qwen7b_bookqa_gradio.py |

### Running Results



https://github.com/svjack/Genshin-Impact-BookQA-LLM/assets/27874014/dd90d1ee-669a-4a12-ab4e-86069064e0a4



https://github.com/svjack/Genshin-Impact-BookQA-LLM/assets/27874014/3c915195-952e-4289-bc88-1e44855c5582




https://github.com/svjack/Genshin-Impact-BookQA-LLM/assets/27874014/99f2ff32-f89e-46c2-8e8e-27a6cda85809



https://github.com/svjack/Genshin-Impact-BookQA-LLM/assets/27874014/b83c2764-fb49-4574-8ac9-be28ff1cf1f1



<br/>

Following are results of two problem in different models.

|    | Question                       | HayStack                                                                                                                                                                                                                                                                                                                                                                                                 | Mistral                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | ChatGLM-6B                                                                                                                                                                                                                                                                                                                                                               | QWen-7B                                                                                                                                                                                                                                                      |
|---:|:---------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|  1 | å²©ç‹å¸å›æ˜¯ä¸€ä¸ªä»€ä¹ˆæ ·çš„äººï¼Ÿ | å²©ç‹å¸å›æ˜¯ä¸€ä½å¤è€çš„ç¥æ˜ï¼Œåœ¨å¤ä»£ä¸­è¢«å¹¿æ³›æ•¬ä»°å’Œä¿¡ä»°ã€‚ä»–æ˜¯å…¬æ­£ã€å†³æ–­ã€å†·é…·æ— ç§çš„ç¥æ˜ï¼Œå¤„äº‹å…¬æ­£ï¼Œå†³æ–­æ— æƒ…ï¼Œä½†ç¼ºä¹å‡¡äººåº”æœ‰çš„æ„Ÿæƒ…ã€‚ä»–çš„æ³•åº¦èƒ½ä¿è¯äº¤æ˜“å…¬å¹³ã€ç”Ÿæ´»å®‰å…¨æœ‰åºï¼ŒåŒæ—¶ä»ä¿¡ä»°ä¸­å¼ºåŒ–ç€è‡ªå·±çš„å­˜åœ¨å’ŒåŠ›é‡ã€‚ä½†å³ä½¿æ˜¯ç¥ï¼Œä¹Ÿæ— æ³•å·¦å³å‡¡äººçš„ä¿¡ä»°å’Œè´¨ç–‘ã€‚å³ä½¿æ˜¯å…¬é“çš„å®ˆæŠ¤ç¥ï¼Œä¹Ÿæ— æ³•å°†è§„åˆ™é’‰å…¥æ¯ä¸ªäººå¿ƒåº•ã€‚åœ¨æŸä¸ªå¥³äººæ¥åˆ°ä»–çš„å·¥åŠè¦æ±‚é›•åˆ»çœŸå®çš„å²©ç‹è‚–åƒçš„æ¡ä»¶ä¸‹ï¼Œä»–é—­é—¨é›•ç¢äº†ä¸‰æ—¥ï¼Œæœ€ç»ˆæˆå½¢äº†ä¸€æ–¹ç‰ç‰Œä¸Šçš„å²©ç‹è‚–åƒã€‚ | å²©ç‹å¸å›æ˜¯ä¸€ä½å¤è€è€Œå¼ºå¤§çš„ç¥æ˜ä¹‹ä¸€ï¼Œåœ¨ç’ƒæœˆåœ°åŒºæ‹¥æœ‰é‡å¤§å½±å“åŠ›ã€‚ä»–æ›¾ç»æœ‰è¿‡ä»™å…½ä½œæˆ˜ï¼Œæˆ˜æ–—ç»“æŸåï¼Œä»™å…½å¤±å»äº†åœ¨ç¥æˆ˜ä¸­å®ˆæŠ¤å‡¡äººçš„æ„ä¹‰ï¼Œä¾¿é€‰æ‹©éšå±…è€Œç”Ÿã€‚æœ‰äº›ä»™å…½ä»ç„¶æ¸´æœ›å®ˆæŠ¤ç’ƒæœˆï¼Œå‘å²©ç‹å¸å›ç¥ˆæ±‚å°†è‚‰èº«åŒ–ä½œæ°¸æ’çš„ç£å²©ï¼Œè¢«å…è®¸æˆå®ã€‚åœ¨ç’ƒæœˆå†å²ä¸­ï¼Œéœ“è£³èŠ±è¢«è§†ä¸ºå²©ç‹å¸å›çš„è±¡å¾ä¹‹ä¸€ï¼ŒåŒæ—¶ä¹Ÿæ˜¯ç’ƒæœˆäººæ—¥å¸¸ç”Ÿæ´»ä¸­å¸¸è§åˆ°çš„ç‰©å“ä¹‹ä¸€ï¼Œç”¨äºåŠ å·¥ç»¸æ®µå’Œåˆ¶é¦™è†ç­‰ç”¨é€”ã€‚åœ¨ç’ƒæœˆå†å²ä¸­ä¹Ÿæœ‰ä¼ è¯´ï¼Œæœ‰ä¸€å—æ˜Ÿæ˜Ÿå è½é€ æˆäº†ç’ƒæœˆåœ°åŒºçš„å·¨æ¸Šå’Œç¾ç‰é‡‘çŸ³ï¼Œè€Œä¸€å°å—æ˜Ÿç¢åœ¨ç¾¤å²©ä¸­è½ä¸‹ï¼Œè¢«ç§°ä¸ºã€Œéç‰é™µã€ï¼Œè¿™ä¸ªå¤è€é—è¿¹ä¸­æœ‰è®¸å¤šå¤è€æ®‹å£ï¼Œä¼ è¯´åå­—ã€Œéç‰ã€æ„å‘³ç€ã€Œç¾ç‰éé€ƒä¹‹å¤„ã€ã€‚åœ¨ç’ƒæœˆæ¸¯è¥¿åŒ—æ–¹æœ‰ä¸€ä½åå«ç‰åŒ çš„äººï¼Œä»–å–œæ¬¢ä»¥ä»¤äººæ„æƒ³ä¸åˆ°çš„æ–¹å¼å®Œæˆå§”æ‰˜ï¼Œå¦‚æœå®¢äººè¦æ±‚ä»–é›•åˆ»ä¸€å¼ å²©ç¥è‚–åƒï¼Œä»–å¯èƒ½ä¼šé›•åˆ»å‡ºä¸€åªé‡çŒªæˆ–è€…å…¶ä»–å¥‡æ€ªå½¢çŠ¶ã€‚ç‰åŒ æ›¾ç»é‡åˆ°äº†ä¸€ä½å¥³äººï¼Œå¥¹è¦æ±‚ä»–é›•åˆ»å‡ºçœŸå®çš„å²©ç¥è‚–åƒï¼Œå¦åˆ™å¥¹ä¸ä¼šä»˜é’±ã€‚ç‰åŒ çº¦å®šäº†ä¸‰æ—¥ä¹‹å†…å®Œæˆä»»åŠ¡ã€‚ç¬¬ä¸€å¤©ç‰åŒ ä¸å¥½å‹å®´é¥®é˜”è®ºï¼Œæ‹’ç»ä»»ä½•å§”æ‰˜ï¼›ç¬¬äºŒå¤©ç‰åŒ å‡ºé—¨ç™»å±±è®¿ç‰ï¼›ç¬¬ä¸‰å¤©ç‰åŒ æ‰å¼€å§‹é—­é—¨é›•ç¢ç’ç‰ï¼Œç›´åˆ°æ·±å¤œæ‰å®Œæˆä»»åŠ¡ã€‚ | å²©ç‹å¸å›æ˜¯ä¸€ä¸ªç¥ç§˜çš„äººç‰©ï¼Œä»–çš„å½¢è±¡åœ¨æ— æ•°çš„æ•…äº‹ä¼ è¯´ä¸­å¾—ä»¥å±•ç°ã€‚ä»–è®¢ç«‹è§„åˆ™ä¸å¥‘çº¦ï¼Œå´ä¸å¼ºè¿«å‡¡äººä»¥æƒå¨çš„å®Œç¾æ¨¡æ¿ç”Ÿæ´»ã€‚ä»–æ·±çŸ¥è§„åˆ™ä¸å¥‘çº¦ä»…æ˜¯æ‰‹æ®µè€Œéç›®çš„ï¼ŒçœŸæ­£çš„å¹³è¡¡ä¸éš½æ°¸åœ¨äºæ¯ä¸€ä¸ªäººçš„è§‰é†’ä¸æŠ‰æ‹©ã€‚ä»–æœ‰ç€æ·±ä¸å¯æµ‹çš„åŠ›é‡å’Œæ™ºæ…§ï¼ŒåŒæ—¶ä¹Ÿæ˜¯ä¸€ä¸ªå–„è‰¯å’Œå®½å®¹çš„äººã€‚è™½ç„¶å…³äºå²©ç‹å¸å›çš„å…·ä½“å½¢è±¡å’Œæ•…äº‹å¾ˆå¤šï¼Œä½†æˆ‘ä»¬æ— æ³•ç¡®å®šä»–çš„çœŸå®èº«ä»½å’Œç‰¹ç‚¹ã€‚åªèƒ½ä»è¿™äº›ä¼ è¯´ä¸­äº†è§£åˆ°ä»–çš„ä¸€äº›ç‰¹ç‚¹å’Œå“è´¨ã€‚ | å²©ç‹å¸å›ä¸ä»…æ˜¯æç“¦ç‰¹å¤§åœ°çš„ç»Ÿæ²»è€…ï¼Œä¹Ÿè¢«ä»–çš„å­æ°‘çºªå¿µã€å´‡æ‹œï¼Œç”šè‡³çˆ±æˆ´ã€‚è¿™è¡¨æ˜ä»–å¯èƒ½æœ‰ç€æ…ˆç¥¥å’Œè¢«å°Šæ•¬çš„ä¸€é¢ï¼ŒåŒæ—¶ä¹Ÿæ˜¾ç¤ºäº†ä»–çš„å¨ä¸¥å’Œç»Ÿæ²»åœ°ä½ã€‚                                                                                                                     |
| 2 | çµå…‰é¢‚çš„å†…å®¹æ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿ   | çµå…‰é¢‚çš„å†…å®¹æ˜¯ä¸€ç§è¯—æ­Œï¼Œå®ƒæè¿°äº†é‚£ä¼½æœ±é‚£å‘€ï¼ˆBodhisattva Avalokitesvaraï¼‰å¾—åˆ°ä¸‡ç§çµå…‰çš„å¸®åŠ©ï¼Œå¹¶ä½¿ç”¨è¿™äº›çµå…‰ä¿æŠ¤å¤§åœ°ã€æ´å‡€äººä»¬ã€å¼€è¾Ÿé“è·¯ç»™å–„çµã€æ»‹å…»èŠ±æµ·çš„å–„çµç­‰ã€‚å®ƒä»¬æ— è®ºæ˜¯åœ¨æ‚²æ€¨çš„æ²³æµä¸­é€†æ¸¡ï¼Œè¿˜æ˜¯é¢å¯¹å¤©å¤–æ¼†é»‘çš„é˜´éœ¾ï¼Œéƒ½èƒ½ä¿æŠ¤ä½è‡ªå·±ã€‚è¿™ç§çµå…‰æ°¸æ’åœ°æŒ‡å¼•äººä»¬ä¸Šå‡é“è·¯ã€‚                                                                                                                                   | è¿™é¦–è¯—ç§°ä¸º"çµå…‰é¢‚"ï¼Œå†…å®¹æè¿°äº†ä¸€ä½äººç±»æˆ–æ˜¯å…¶ä»–å®ä½“ï¼Œå¾—åˆ°äº†ä¸‡ç§çµå…‰çš„å¸®åŠ©ï¼Œå·²ç»è¶…è¶Šäº†æ­»äº¡ï¼Œæ´å‡€äº†é«˜å¤©çš„æ¸Šè–®ï¼Œæ´—å‡€äº†æ— ç½ªä¹‹äººçš„ç½ªå­½ï¼Œåœ¨å¤§åœ°ä¸­è•´è—äº†ä¸€åˆ‡ä¸šç§ã€‚è¿™ä½å®ä½“åœ¨ä¸–é—´çš„è£è€€åªæ˜¯ç§å­ç°è¡Œçš„å¹»è±¡ï¼Œä½†å®ƒå·²ç»é€†æ¸¡æ‚²æ€¨çš„æ²³æµï¼Œæ¸´é¥®ç”˜éœ²ï¼Œä¸ºå–„çµå¼€è¾Ÿé“è·¯ï¼Œä½¿æ™ºæ…§çš„æ…ˆå…‰æ™®ç…§å››æ–¹ã€‚å®ƒå¾—åˆ°äº†ä¸‡ç§çµå…‰çš„ä¿æŠ¤ï¼Œæ»‹å…»ç€èŠ±æµ·çš„å–„çµï¼Œå®ƒä»¬åœ¨æ¸´æœ›æ´å‡€çš„å¿ƒä¸­ï¼Œå³ä½¿å¤©å¤–æ¼†é»‘çš„é˜´éœ¾å‡ºç°ä¹Ÿæ— æ³•ä¾µèš€å®ƒä»¬çš„èº«å½¢ã€‚                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | çµå…‰é¢‚çš„å†…å®¹ä¸»è¦æ˜¯æè¿°äº†çµå…‰çš„åŠ›é‡å’Œä½œç”¨ï¼Œä»¥åŠå®ƒå¯¹äººç±»å’Œè‡ªç„¶çš„ç¥ç¦å’Œä¿æŠ¤ã€‚å…¶ä¸­æåˆ°äº†çµå…‰æ´—å‡€äº¡è€…çš„ç½ªå­½ï¼Œå¸®åŠ©äººä»¬è¶…åº¦åˆ°æ— æ‚²è‹¦çš„å‡€åœŸï¼›çµå…‰ä¹Ÿæ´å‡€é«˜å¤©çš„æ¸Šè–®ï¼Œä½¿æ±¡æ³¥é€€å»ï¼Œæ…‘æœäºæ­£æ³•ï¼›çµå…‰å°†æŒ‡å¼•äººä»¬ä¸Šå‡çš„é“è·¯ã€‚çµå…‰è¿˜æ»‹å…»ç€èŠ±æµ·çš„å–„çµï¼Œä¿æŠ¤ç€è‰æœ¨ä¹‹ç¥çš„æœ«è£”å’Œç™¾æˆ˜åŠ«ä½™çš„å‹‡å£«ï¼Œä½¿å®ƒä»¬èº«å½¢ä¸å—å¤©å¤–æ¼†é»‘é˜´éœ¾çš„ä¾µèš€ã€‚                                                             | çµå…‰é¢‚çš„å†…å®¹ä¸»è¦æ˜¯å¯¹çµå…‰çš„æ­Œé¢‚å’Œç¥ˆæ±‚ã€‚è¯—ä¸­æè¿°äº†å¾—åŠ©äºä¸‡ç§çµå…‰çš„äººç‰©å·²ç»è¶…åº¦å°˜åœŸï¼Œæ´—å‡€ç½ªå­½ï¼Œå¾€ç”Ÿå‡€åœŸã€‚åŒæ—¶ï¼Œè¯—ä¸­è¿˜æç»˜äº†åœ¨é»‘æš—ä¸­é€†æµè€Œä¸Šçš„å½¢è±¡ï¼Œä»¥åŠä»–ä»¬å¯¹äºå–„çµå¼€è¾Ÿé“è·¯ï¼Œæ™ºæ…§æ…ˆå…‰æ™®ç…§å››æ–¹çš„ä½œç”¨ã€‚æ€»çš„æ¥è¯´ï¼Œçµå…‰é¢‚çš„å†…å®¹å……æ»¡ç§¯æå‘ä¸Šã€è¿½æ±‚çœŸç†å’Œæ™ºæ…§çš„æ„æ¶µã€‚ |

For more compare results, you can take a look at. [compare_resuilt](compare_result.md)


### Note
I recommand you run the demo on GPU (10GB gpu memory is enough, all examples have tested on single GTX 1080Ti or GTX 3060) <br/><br/>

## Datasets and Models
### Datasets
|Name | Type | HuggingFace Dataset link |
|---------|--------|--------|
| svjack/genshin_book_chunks_with_qa_sp | Genshin Impact Book Content | https://huggingface.co/datasets/svjack/genshin_book_chunks_with_qa_sp |
| svjack/bge_small_book_chunks_prebuld | Genshin Impact Book Embedding | https://huggingface.co/datasets/svjack/bge_small_book_chunks_prebuld |

### Basic Models
|Name | Type | HuggingFace Model link |
|---------|--------|--------|
| svjack/bge-small-book-qa | Embedding model | https://huggingface.co/svjack/bge-small-book-qa |
| svjack/setfit_info_cls | Text Classifier | https://huggingface.co/svjack/setfit_info_cls |

### LLM Models
|Name | Type | HuggingFace Model link |
|---------|--------|--------|
| svjack/chatglm3-6b-bin | ChatGLM3-6B 4bit quantization | https://huggingface.co/svjack/chatglm3-6b-bin |
| svjack/mistral-7b | Mistral-7B 4bit quantization | https://huggingface.co/svjack/mistral-7b |

<br/><br/>

## Architecture
This project has a traditional RAG structure.<br/>
[svjack/bge-small-book-qa](https://huggingface.co/svjack/bge-small-book-qa) is a self-trained embedding model
for recall genshin book contents (split by langChain TextSplitter). [svjack/setfit_info_cls](https://huggingface.co/svjack/setfit_info_cls) is a self-trained text classifier for determine whether the content is relevant to the query. <br/> <br/>

LLM Part have 4 different llm frameworks: [HayStack](https://github.com/deepset-ai/haystack) [chatglm.cpp](https://github.com/li-plus/chatglm.cpp) [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) [ollama](https://github.com/ollama/ollama) one can choose to answer the query based on the content recalled by embedding and filter out by text classifier.<br/> 

### Note
[HayStack](https://github.com/deepset-ai/haystack) [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) and [ollama](https://github.com/ollama/ollama) are repos contains many different llms. You can try to use different llms and change the model name or model 
file in the gradio scripts.<br/> * For the ability of understanding the query and context, i recommand you use Mistral-7B in Huggingface Inference Api or Intel/neural-chat in ollama. <br/> * For the ability of answer quality in Chinese, i recommand you Qwen-7B in ollama or ChatGLM3-6B in chatglm.cpp. 

<br/><br/>

<!-- CONTACT -->
## Contact

<!--
Your Name - [@your_twitter](https://twitter.com/your_username) - email@example.com
-->
svjack - https://huggingface.co/svjack - svjackbt@gmail.com - ehangzhou@outlook.com

<!--
Project Link: [https://github.com/your_username/repo_name](https://github.com/your_username/repo_name)
-->
Project Link:[https://github.com/svjack/Genshin-Impact-BookQA-LLM](https://github.com/svjack/Genshin-Impact-BookQA-LLM)


<!-- ACKNOWLEDGEMENTS -->
## Acknowledgements
* [Genshin Impact](https://genshin.hoyoverse.com/en/)
* [Huggingface](https://huggingface.co)
* [Mistral-7B](https://mistral.ai/news/announcing-mistral-7b/)
* [LangChain](https://github.com/langchain-ai/langchain)
* [SetFit](https://github.com/huggingface/setfit)
* [HayStack](https://github.com/deepset-ai/haystack)
* [chatglm.cpp](https://github.com/li-plus/chatglm.cpp)
* [llama-cpp-python](https://github.com/abetlen/llama-cpp-python)
* [ollama](https://github.com/ollama/ollama)
* [svjack](https://huggingface.co/svjack)





