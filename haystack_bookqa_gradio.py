from gradio_client import Client
client = Client("https://svjack-entity-property-extractor-zh.hf.space")

import pandas as pd
import numpy as np
import os
import re

from langchain.vectorstores import FAISS
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
from langchain import chains
from rapidfuzz import fuzz

import pandas as pd

from haystack.components.generators.chat import HuggingFaceTGIChatGenerator
from haystack.dataclasses import ChatMessage
import pandas as pd
import numpy as np

from huggingface_hub import snapshot_download

if not os.path.exists("genshin_book_chunks_with_qa_sp"):
    path = snapshot_download(
        repo_id="svjack/genshin_book_chunks_with_qa_sp",
        repo_type="dataset",
        local_dir="genshin_book_chunks_with_qa_sp",
        local_dir_use_symlinks = False
    )

if not os.path.exists("bge_small_book_chunks_prebuld"):
    path = snapshot_download(
        repo_id="svjack/bge_small_book_chunks_prebuld",
        repo_type="dataset",
        local_dir="bge_small_book_chunks_prebuld",
        local_dir_use_symlinks = False
    )

model_id = "mistralai/Mistral-7B-Instruct-v0.2"
HF_TOKEN = os.environ.get("HF_READ_TOKEN")
tgi_chat_generator = HuggingFaceTGIChatGenerator(model=model_id, token=HF_TOKEN,
                                        #stop_words = [".",  "ã€‚"]
                                        )
tgi_chat_generator.warm_up()

def chat_messages(message, history,
    max_length = 128, show_process = False):
    flatten_history = []
    for a, b in history:
        flatten_history.append(
                #chatglm_cpp.ChatMessage(role="user", content=a)
                ChatMessage.from_user(a)
            )
        flatten_history.append(
                #chatglm_cpp.ChatMessage(role="assistant", content=b)
                ChatMessage.from_assistant(b)
            )
    response = tgi_chat_generator.run(
    flatten_history + [
    ChatMessage.from_user(message)
    ]
    , generation_kwargs={"max_new_tokens": max_length})
    #print(response["replies"][0].content)
    yield response["replies"][0].content

'''
query = "è­¦å¯Ÿæ˜¯å¦‚ä½•ç ´è·é‚ªæ¶è®¡åˆ’çš„ï¼Ÿ" ## è­¦ æ‰§å¾‹ ç›—
k = 10
uniform_recall_docs_to_pairwise_cos(
    query,
    docsearch_bge_loaded.similarity_search_with_score(query, k = k, ),
    bge_book_embeddings
)
'''
def uniform_recall_docs_to_pairwise_cos(query ,doc_list, embeddings):
    assert type(doc_list) == type([])
    from langchain.evaluation import load_evaluator
    from langchain.evaluation import EmbeddingDistance
    hf_evaluator = load_evaluator("pairwise_embedding_distance", embeddings=embeddings,
                              distance_metric = EmbeddingDistance.COSINE)
    return sorted(pd.Series(doc_list).map(lambda x: x[0].page_content).map(lambda x:
        (x ,hf_evaluator.evaluate_string_pairs(prediction=query, prediction_b=x)["score"])
    ).values.tolist(), key = lambda t2: t2[1])

'''
sort_by_kw("æ·±æ¸Šä½¿å¾’", book_df)["content_chunks_formatted"].head(5).values.tolist() ### æ·±æ¸Š
'''
def sort_by_kw(kw, book_df):
    req = book_df.copy()
    req["sim_score"] = req.apply(
    lambda x:
    max(map(lambda y: fuzz.ratio(y, kw) ,eval(x["person"]) + eval(x["locate"]) + eval(x["locate"]))) if \
    eval(x["person"]) + eval(x["locate"]) + eval(x["locate"]) else 0
    , axis = 1
)
    req = req.sort_values(by = "sim_score", ascending = False)
    return req

def recall_chuncks(query, docsearch, embedding, book_df,
    sparse_threshold = 30,
    dense_top_k = 10,
    rerank_by = "emb",
):
    sparse_output = sort_by_kw(query, book_df)[["content_chunks_formatted", "sim_score"]]
    sparse_output_list = sparse_output[
        sparse_output["sim_score"] >= sparse_threshold
    ]["content_chunks_formatted"].values.tolist()
    dense_output = uniform_recall_docs_to_pairwise_cos(
        query,
        docsearch.similarity_search_with_score(query, k = dense_top_k,),
        embedding
    )
    for chunck, score in dense_output:
        if chunck not in sparse_output_list:
            sparse_output_list.append(chunck)
    if rerank_by == "emb":
        from langchain.evaluation import load_evaluator
        from langchain.evaluation import EmbeddingDistance
        hf_evaluator = load_evaluator("pairwise_embedding_distance", embeddings=embedding,
                                  distance_metric = EmbeddingDistance.COSINE)
        return pd.Series(sorted(pd.Series(sparse_output_list).map(lambda x:
            (x ,hf_evaluator.evaluate_string_pairs(prediction=query, prediction_b=x)["score"])
        ).values.tolist(), key = lambda t2: t2[1])).map(lambda x: x[0]).values.tolist()
    else:
        sparse_output_list = sorted(sparse_output_list, key = lambda x: fuzz.ratio(x, query), reverse = True)
    return sparse_output_list

def reduce_list_by_order(text_list, as_text = False):
    if not text_list:
        return
    df = pd.DataFrame(
        list(map(lambda x: (x.split("\n")[0], x.split("\n")[1], "\n".join(x.split("\n")[2:])), text_list))
    ).groupby([0, 1])[2].apply(list).map(lambda x: sorted(x, key = len, reverse=True)).map(
        "\n\n".join
    ).reset_index()
    d = dict(df.apply(lambda x: ((x.iloc[0], x.iloc[1]), x.iloc[2]), axis = 1).values.tolist())
    #return df
    order_list = []
    for x in text_list:
        a, b = x.split("\n")[0], x.split("\n")[1]
        if not order_list:
            order_list = [[a, [b]]]
        elif a in list(map(lambda t2: t2[0], order_list)):
            order_list[list(map(lambda t2: t2[0], order_list)).index(a)][1].append(b)
        elif a not in list(map(lambda t2: t2[0], order_list)):
            order_list.append([a, [b]])
    df = pd.DataFrame(pd.DataFrame(order_list).explode(1).dropna().apply(
        lambda x: (x.iloc[0], x.iloc[1], d[(x.iloc[0], x.iloc[1])]), axis = 1
    ).values.tolist()).drop_duplicates()
    if as_text:
        return "\n\n".join(
            df.apply(lambda x: "{}\n{}\n{}".format(x.iloc[0], x.iloc[1], x.iloc[2]), axis = 1).values.tolist()
        )
    return df

def build_gpt_prompt(query, docsearch, embedding, book_df, max_context_length = 4090):
    l = recall_chuncks(query, docsearch, embedding, book_df)
    context = reduce_list_by_order(l, as_text = True)
    context_l = []
    for ele in context.split("\n"):
        if sum(map(len, context_l)) >= max_context_length:
            break
        context_l.append(ele)
    context = "\n".join(context_l).strip()
    template = """ä½¿ç”¨ä»¥ä¸‹ä¸Šä¸‹æ–‡æ¥å›ç­”æœ€åçš„é—®é¢˜ã€‚å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œå°±è¯´ä½ ä¸çŸ¥é“ï¼Œä¸è¦è¯•å›¾ç¼–é€ ç­”æ¡ˆã€‚å°½é‡ä½¿ç­”æ¡ˆç®€æ˜æ‰¼è¦ã€‚æ€»æ˜¯åœ¨å›ç­”çš„æœ€åè¯´â€œè°¢è°¢ä½ çš„æé—®ï¼â€ã€‚

{context}

é—®é¢˜: {question}
æœ‰ç”¨çš„å›ç­”:"""
    return template.format(
        **{
            "context": context,
            "question": query
        }
    )

def collect_prompt_to_hist_list(prompt, add_assistant = False):
    l = pd.Series(prompt.split("\n\n")).map(lambda x: x.strip()).values.tolist()
    ll = []
    for ele in l:
        if not ll:
            ll.append(ele)
        else:
            if ele.startswith("æ–‡ç« æ ‡é¢˜ï¼š") or ele.startswith("é—®é¢˜:"):
                ll.append(ele)
            else:
                ll[-1] += ("\n\n" + ele)
    if add_assistant:
        ll_ = []
        for i in range(len(ll)):
            if i == 0:
                ll_.append((ll[i], "å¥½çš„ã€‚"))
            elif i < len(ll) - 1:
                ll_.append((ll[i], "æˆ‘è¯»æ‡‚äº†ã€‚"))
            else:
                ll_.append((ll[i], ""))
        return ll_
    else:
        return ll

def row_to_content_ask(r):
    question = r["question"]
    content_list = r["content_list"]
    assert type(content_list) == type([])
    content_prompt_list = pd.Series(content_list).map(
        lambda x:  '''
    {}\nä»ä¸Šé¢çš„ç›¸å…³çš„å™è¿°ä¸­æŠ½å–åŒ…å«"{}"ä¸­è¯æ±‡çš„ç›¸å…³è¯­æ®µã€‚
    '''.format(x, question).strip()
    ).values.tolist()
    return content_prompt_list

def entity_extractor_by_hf(query,
    show_process = False, max_length = 512,
    return_out_text = False,
    ):
    import re
    hist = [
    ['è¯·ä»ä¸‹é¢çš„å¥å­ä¸­æå–å®ä½“å’Œå±æ€§ã€‚ä¸éœ€è¦è¿›è¡Œè¿›ä¸€æ­¥è§£é‡Šã€‚', 'å¥½çš„ã€‚'],
     ['é—®é¢˜ï¼šå®æ³¢åœ¨å“ªä¸ªçœä»½ï¼Ÿ', 'å®ä½“ï¼šå®æ³¢ å±æ€§ï¼šçœä»½'],
     ['é—®é¢˜ï¼šä¸­å›½çš„è´§å¸æ˜¯ä»€ä¹ˆï¼Ÿ', 'å®ä½“ï¼šä¸­å›½ å±æ€§ï¼šè´§å¸'],
     ['é—®é¢˜ï¼šç™¾æ…•å¤§ä¸‰è§’åœ¨ä»€ä¹ˆåœ°æ–¹ï¼Ÿ', 'å®ä½“ï¼šç™¾æ…•å¤§ä¸‰è§’ å±æ€§ï¼šåœ°æ–¹'],
     ['é—®é¢˜ï¼šè°æ˜¯æœ€å¯çˆ±çš„äººï¼Ÿ', "å®ä½“ï¼šäºº å±æ€§ï¼šå¯çˆ±"],
     ['é—®é¢˜ï¼šé»„æ²³çš„æ‹ç‚¹åœ¨å“ªé‡Œï¼Ÿ', "å®ä½“ï¼šé»„æ²³ å±æ€§ï¼šæ‹ç‚¹"],
     #['é—®é¢˜ï¼šé­”ç¥å½’ç»ˆåœ¨å“ªé‡Œï¼Ÿ', 'å®ä½“ï¼šå½’ç»ˆ å±æ€§ï¼šå“ªé‡Œ'],
     #["ç‰ç±³çš„å¼•è¿›æ—¶é—´æ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ", ""]
     ]

    out_text = chat_messages("é—®é¢˜ï¼š{}".format(query),
        hist,
    )
    req = ""
    for ele in out_text:
        req = ele
    out_text = req

    if return_out_text:
        return out_text
    e_list = re.findall(r"å®ä½“(.*?)å±æ€§", out_text.replace("\n", " "))
    if e_list:
        return re.findall(u"[\u4e00-\u9fa5]+" ,e_list[0])
    return None

def unzip_string(x, size = 2):
    if len(x) <= size:
        return [x]
    req = []
    for i in range(len(x) - size + 1):
        req.append(x[i: i + size])
    return req

def entity_extractor_by_adapter(x):
    import json
    result = client.predict(
    		x,	# str  in 'question' Textbox component
    		api_name="/predict"
    )
    with open(result, "r") as f:
        req = json.load(f)
    req_list = req.get("E-TAG", [])
    req_ = []
    for ele in req_list:
        for x in unzip_string(ele, 2):
            if x not in req_:
                req_.append(x)
    return req_

##### maybe 0.5
def query_content_ask_func(question, content_list,
    setfit_model, show_process = False, max_length = 1024):
    ask_list = row_to_content_ask(
        {
            "question": question,
            "content_list": content_list
        }
    )
    #return ask_list
    req = []
    for prompt in ask_list:

        out_text = chat_messages(prompt + "å¦‚æœæ²¡æœ‰æåˆ°ç›¸å…³å†…å®¹ï¼Œè¯·å›ç­”ä¸çŸ¥é“ã€‚ä½¿ç”¨ä¸­æ–‡è¿›è¡Œå›ç­”ï¼Œä¸è¦åŒ…å«ä»»ä½•è‹±æ–‡ã€‚",
                [], show_process = show_process, max_length = max_length
            )
        req_ = ""
        for ele in out_text:
            req_ = ele
        out_text = req_

        req.append(out_text)
    d = {
            "question": question,
            "content_list": content_list
        }
    assert len(req) == len(ask_list)
    d["question_content_relate_list"] = req
    d["relate_prob_list"] = setfit_model.predict_proba(
               req
        ).numpy()[:, 1].tolist()
    return d

def build_relate_ask_list(query, docsearch_bge_loaded, bge_book_embeddings, book_df,
                          setfit_model, as_content_score_df = True,
                          show_process = False, add_relate_entities = False,
                          max_length = 1024):
    prompt = build_gpt_prompt(query, docsearch_bge_loaded, bge_book_embeddings, book_df)
    prompt_list = collect_prompt_to_hist_list(prompt)
    question = prompt_list[-1].split("\n")[0]
    content_list = prompt_list[1:-1]

    d = query_content_ask_func(question, content_list,
            setfit_model, show_process = show_process)

    #entity_list = entity_extractor_by_hf(query,
    # show_process = show_process, max_length = max_length)
    entity_list = entity_extractor_by_adapter(query)
    if type(entity_list) != type([]):
        entity_list = []

    d["in_content_entity_list"] = list(map(lambda x:
        list(filter(lambda e: e in x, entity_list))
    , d["content_list"]))

    if add_relate_entities:
        relate_content_entity_list = [[]] * len(content_list)

        for entity in entity_list:
            entity_content_score_d = query_content_ask_func(entity, d["content_list"],
                setfit_model, show_process = show_process)
            lookup_df = pd.DataFrame(
                list(zip(*[entity_content_score_d["content_list"],
                entity_content_score_d["relate_prob_list"]]))
            )
            for ii, (i, r) in enumerate(lookup_df.iterrows()):
                if r.iloc[1] >= 0.5 and entity not in relate_content_entity_list[ii]:
                    #relate_content_entity_list[ii].append(entity)
                    relate_content_entity_list[ii] = relate_content_entity_list[ii] + [entity]

        d["relate_content_entity_list"] = relate_content_entity_list

    if as_content_score_df:
        if add_relate_entities:
            df = pd.concat(
                [
                    pd.Series(d["content_list"]).map(lambda x: x.strip()),
                    pd.Series(d["in_content_entity_list"]),
                    pd.Series(d["relate_content_entity_list"]),
                    pd.Series(d["question_content_relate_list"]).map(lambda x: x.strip()),
                    pd.Series(d["relate_prob_list"])
                ], axis = 1
            )
            df.columns = ["content", "entities", "relate_entities", "relate_eval_str", "score"]
        else:
            df = pd.concat(
                [
                    pd.Series(d["content_list"]).map(lambda x: x.strip()),
                    pd.Series(d["in_content_entity_list"]),
                    #pd.Series(d["relate_content_entity_list"]),
                    pd.Series(d["question_content_relate_list"]).map(lambda x: x.strip()),
                    pd.Series(d["relate_prob_list"])
                ], axis = 1
            )
            df.columns = ["content", "entities", "relate_eval_str", "score"]
        req = []
        entities_num_list = df["entities"].map(len).drop_duplicates().dropna().sort_values(ascending = False).\
            values.tolist()
        for e_num in entities_num_list:
            req.append(
            df[
                df["entities"].map(lambda x: len(x) == e_num)
            ].sort_values(by = "score", ascending = False)
            )
        return pd.concat(req, axis = 0)
        #df = df.sort_values(by = "score", ascending = False)
        #return df
    return d

def run_all(query, docsearch_bge_loaded, bge_book_embeddings, book_df,
                          setfit_model, only_return_prompt = False,
                          use_gf4_on_qa = False):
    df = build_relate_ask_list(query, docsearch_bge_loaded, bge_book_embeddings, book_df,
                              setfit_model, show_process=False)
    info_list = df[
        df.apply(
            lambda x: x["score"] >= 0.5 and bool(x["entities"]), axis = 1
        )
    ].values.tolist()
    if not info_list:
        return df, info_list, "æ²¡æœ‰ç›¸å…³å†…å®¹ï¼Œè°¢è°¢ä½ çš„æé—®ã€‚"
    prompt = '''
é—®é¢˜: {}
æ ¹æ®ä¸‹é¢çš„å†…å®¹å›ç­”ä¸Šé¢çš„é—®é¢˜ï¼Œå¦‚æœæ— æ³•æ ¹æ®å†…å®¹ç¡®å®šç­”æ¡ˆï¼Œè¯·å›ç­”ä¸çŸ¥é“ã€‚
{}
'''.format(query, "\n\n".join(pd.Series(info_list).map(lambda x: x[0]).values.tolist()))
    if only_return_prompt:
        return df, info_list, prompt

    q_head = "\n".join(prompt.split("\n")[:2])
    c_tail = "\n".join(prompt.split("\n")[2:])[:4000]
    if use_gf4_on_qa:
        out_text = chat_messages_gf4(
            c_tail + "\n" + q_head.replace("ä¸‹é¢çš„å†…å®¹å›ç­”ä¸Šé¢çš„é—®é¢˜", "ä¸Šé¢çš„å†…å®¹å›ç­”é—®é¢˜") + "ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚",
            [], show_process = False, max_length = 512
        )
    else:
        out_text = chat_messages(
            c_tail + "\n" + q_head.replace("ä¸‹é¢çš„å†…å®¹å›ç­”ä¸Šé¢çš„é—®é¢˜", "ä¸Šé¢çš„å†…å®¹å›ç­”é—®é¢˜") + "ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚",
            [], show_process = False, max_length = 512
        )
    req_ = ""
    for ele in out_text:
        req_ = ele
    out_text = req_

    return df, info_list, out_text

import gradio as gr

#book_df = pd.read_csv("genshin_book_chunks_with_qa_sp.csv")
book_df = pd.read_csv("genshin_book_chunks_with_qa_sp/genshin_book_chunks_with_qa_sp.csv")
book_df["content_chunks"].dropna().drop_duplicates().shape

book_df["content_chunks_formatted"] = book_df.apply(
        lambda x: "æ–‡ç« æ ‡é¢˜ï¼š{}\nå­æ ‡é¢˜ï¼š{}\nå†…å®¹ï¼š{}".format(x["title"], x["sub_title"], x["content_chunks"]),
        axis = 1
    )

texts = book_df["content_chunks_formatted"].dropna().drop_duplicates().values.tolist()

#embedding_path = "bge-small-book-qa/"
embedding_path = "svjack/bge-small-book-qa"
bge_book_embeddings = HuggingFaceEmbeddings(model_name=embedding_path)
docsearch_bge_loaded = FAISS.load_local("bge_small_book_chunks_prebuld/", bge_book_embeddings,
                                       allow_dangerous_deserialization = True
                                       )

from setfit import SetFitModel
#setfit_model = SetFitModel.from_pretrained("setfit_info_cls")
setfit_model = SetFitModel.from_pretrained("svjack/setfit_info_cls")

with gr.Blocks() as demo:
    title = gr.HTML(
            """<h1 align="center"> <font size="+3"> Genshin Impact Book QA Haystack Demo ğŸ“ˆ </font> </h1>""",
            elem_id="title",
    )

    with gr.Column():
        with gr.Row():
            query = gr.Text(label = "è¾“å…¥é—®é¢˜ï¼š", lines = 1, interactive = True, scale = 5.0)
            run_button = gr.Button("å¾—åˆ°ç­”æ¡ˆ")
        output = gr.Text(label = "å›ç­”ï¼š", lines = 5, interactive = True)
        recall_items = gr.JSON(label = "å¬å›ç›¸å…³å†…å®¹", interactive = False)

    with gr.Row():
        gr.Examples(
            [
             'ä¸˜ä¸˜äººæœ‰å“ªäº›ç”Ÿæ´»ä¹ æƒ¯ï¼Ÿ',
             'å²©ç‹å¸å›å’Œå½’ç»ˆæ˜¯ä»€ä¹ˆå…³ç³»ï¼Ÿ',
             'ç›ä¹‹é­”ç¥çš„ä¸‹åœºæ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿ',
             'å²©ç‹å¸å›æ˜¯ä¸€ä¸ªä»€ä¹ˆæ ·çš„äººï¼Ÿ',
             'ç™½å¤œå›½çš„å­æ°‘é­é‡äº†ä»€ä¹ˆï¼Ÿ',
             'å¤§è›‡å±…ä½åœ¨å“ªé‡Œï¼Ÿ',
             'çŠç‘šå®«æœ‰å“ªäº›ä¼ è¯´ï¼Ÿ',
             'çµå…‰é¢‚çš„å†…å®¹æ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿ',
             'è¿å¿ƒç è®²äº†ä¸€ä»¶ä»€ä¹ˆäº‹æƒ…ï¼Ÿ',
             'æ¢“å¿ƒæ˜¯è°ï¼Ÿ',
             'ç’ƒæœˆæœ‰å“ªäº›æ•…äº‹ï¼Ÿ',
             'è½»ç­–åº„æœ‰å“ªäº›æ•…äº‹ï¼Ÿ',
             'ç‘¶å…‰æ»©æœ‰å“ªäº›æ•…äº‹ï¼Ÿ',
             'ç¨»å¦»æœ‰å“ªäº›æ•…äº‹ï¼Ÿ',
             'æµ·ç¥‡å²›æœ‰å“ªäº›æ•…äº‹ï¼Ÿ',
             'é¡»å¼¥æœ‰å“ªäº›æ•…äº‹ï¼Ÿ',
             'è’™å¾·æœ‰å“ªäº›æ•…äº‹ï¼Ÿ',
             'ç’ƒæœˆæœ‰å“ªäº›å¥‡çå¼‚å®ï¼Ÿ',
             'ç‹¸çŒ«å’Œå¤©ç‹—æ˜¯ä»€ä¹ˆå…³ç³»ï¼Ÿ',
            ],
            inputs = query,
            label = "è¢«ä¹¦ç›®å†…å®¹åŒ…å«çš„é—®é¢˜"
        )
    with gr.Row():
        gr.Examples(
            [
             'çˆ±ä¸½ä¸å¥³å£«æ˜¯å¯è‰çš„å¦ˆå¦ˆå—ï¼Ÿ',
             'æ‘˜æ˜Ÿå´–æ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿ',
             'ä¸˜ä¸˜äººä½¿ç”¨çš„æ˜¯ä»€ä¹ˆæ–‡å­—ï¼Ÿ',
             'æ·±æ¸Šä½¿å¾’å“ªé‡Œæ¥çš„ï¼Ÿ',
             'å‘æ¡æœºå…³å¯ä»¥ç”¨æ¥åšä»€ä¹ˆï¼Ÿ',
             'é‚£å…ˆæœ±é‚£åšäº†ä»€ä¹ˆï¼Ÿ',
            ],
            inputs = query,
            label = "æ²¡æœ‰è¢«ä¹¦ç›®æ˜ç¡®æåˆ°çš„é—®é¢˜"
        )

    run_button.click(lambda x:
        run_all(x, docsearch_bge_loaded, bge_book_embeddings, book_df,
                                setfit_model = setfit_model)[1:],
        query, [recall_items, output]
    )

demo.queue(max_size=4, concurrency_count=1).launch(debug=True, show_api=False, share = True)
